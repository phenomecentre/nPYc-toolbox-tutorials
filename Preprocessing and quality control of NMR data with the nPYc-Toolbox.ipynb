{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and quality control of NMR data with the nPYc-Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use the NMR data processing modules of the nPYc-Toolbox, to import and perform some basic preprocessing and quality control of NMR data and to output a final high quality dataset ready for data modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of how to install all of the required dependencies and to set up your computing environment can be found in 'document.txt', and full documentation for the nPYc-Toolbox can be found on [read the docs](https://npyc-toolbox.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nPYc-Toolbox has been developed based on the quality control criteria previously described in [Dona et al. 2014](https://www.ncbi.nlm.nih.gov/pubmed/25180432)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this example (NMR DevSet Dataset) is comprised of six samples of pooled human urine, aliquoted, and independently prepared and measured by 1H NMR spectroscopy. Each source sample was separately prepared and assayed thirteen times. A pooled QC sample and independent external reference of a comparable matrix was also acquired to assist in assessing analytical precision. See the Metabolights Study [MTBLS694](https://www.ebi.ac.uk/metabolights/MTBLS694)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the nPYc-Toolbox and configure Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the nPYc-Toolbox\n",
    "import nPYc\n",
    "\n",
    "# Import enumerations for sample type\n",
    "from nPYc.enumerations import VariableType, DatasetLevel, AssayRole, SampleType\n",
    "\n",
    "# Import normalisation objects for data normalisation\n",
    "from nPYc.utilities.normalisation import NullNormaliser, TotalAreaNormaliser, ProbabilisticQuotientNormaliser\n",
    "\n",
    "# Import matplotlib plotting, configure the Jupyter notebook to plot inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up plotly to work in offline mode with the notebook\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and preprocess NMR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the raw NMR data (Bruker format) into an nPYc-Toolbox [nmrData object](https://npyc-toolbox.readthedocs.io/en/latest/objects.html#nmrdataset)\n",
    "\n",
    "The \"rawDataPath\" parameter sets the location of the NMR raw data.\n",
    "\n",
    "The NMR DevSet Dataset is located xxxxxxx. This folder contains 93 directories, each corresponding to a spectrum acquired with the ‘noesygppr1d’ pulse sequence. The Fourier Transform, apodization and phasing have already been performed with the vendor software (ie, TopSpin).\n",
    "\n",
    "The “sop” parameter points to a file which contains a set of parameters to use during data import and pre-processing. Each SOP file is encoded in JSON format. For full details see [Table 6 SOP parameters for all NMRDataset objects](https://npyc-toolbox.readthedocs.io/en/latest/configuration/configurationSOPs.html)\n",
    "\n",
    "The nPYc-Toolbox contains two default SOP files, GenericNMRUrine and GenericNMRBlood. These contain the recommended parameters for import and quality control of human urine and plasma/serum biofluid, respectively. Since this is a urine biofluid dataset, we will use the GenericNMRUrine ‘sop’ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPath = '/path to NMR raw data files'\n",
    "pulseProgram = 'noesygppr1d'\n",
    "sop = 'GenericNMRurine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line triggers the pre-processing of the NMR spectra and creates an object representing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrData = nPYc.NMRDataset(rawDataPath, pulseProgram=pulseProgram, sop=sop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the arguments present in the SOP file can be overwritten by passing to the data import command directly, without having to modify or generate a SOP file. For example, if the user wants to import all the ‘noesygppr1d’, but interpolate the spectra to a higher resolution, the argument variable Size can be overridden in the following manner:\n",
    "\n",
    "```\n",
    "nmrData = nPYc.NMRDataset(rawDataPath, pulseProgram=pulseProgram, sop=sop, variableSize=64000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each nPYc Dataset object contains a name that can be changed as shown in the next cell. This name will be used in the summary and visualization reports and exported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmrData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82d33e7fa44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmrData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nPYc NMR Tutorial dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nmrData' is not defined"
     ]
    }
   ],
   "source": [
    "nmrData.name = 'nPYc NMR Tutorial dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import sample metadata and match to acquired NMR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default way to add sample metadata to an NMRDataset object is to prepare a CSV file which follows the set of conventions as described in the previous section (Metadata CSV file) and use the following command:\n",
    "\n",
    "More information about the CSV file format used for linking metadata, as well as the study design nomenclatures used in the nPYc-Toolbox can be found in the toolbox documentation (https://npyc-toolbox.readthedocs.io/en/latest/nomenclature.html).\n",
    "\n",
    "By default, all imported spectra are considered ‘equal’ in terms of their role in the assay/overall experiment, and are assumed to correspond to a regular study sample. But in many instances, including the dataset we are using in this tutorial, a series of quality control samples can be acquired as well. In this case, we have samples with different roles in the overall assay QC process.\n",
    "\n",
    "Although it is not necessary to provide extra information about the samples to use the nPYc-Toolbox to process and QC an NMR dataset, the extra information will enhance the quality of the reports generated in the next section. It is also recommended to add metadata related to run order, batch effects and other potential analytical confounders, so we can assess their influence in the multivariate reports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmrData.addSampleInfo(descriptionFormat='Basic CSV', filePath='/path to sample metadata file/PipelineTest 1D NMR Basic CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Or directly inspect the sample or feature metadata, and the raw measurements:\n",
    "\n",
    "dataset.sampleMetadata\n",
    "dataset.featureMetadata\n",
    "\n",
    "dataset.intensityData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Sample & Feature Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate sample summary report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default all summary reports (with the exception of the final report) will be output only to this notebook. The notebook (including outputs) can be saved using >File>Save and Checkpoint. However, if html copies of any reports are required these can be automatically saved to the save directory by adding the optional input argument output=pathToSaveDirectory.\n",
    "\n",
    "saveDir = '/path to save outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        This summary can be used to check the expected samples against those acquired (for example, sample numbers, sample type, samples missing from acquisition or lacking metadata information).\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(nmrData, 'sample summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feature summary report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        The feature summary report provides visualisations summarising the quality of the dataset and highlighting any problematic areas. These include: a chemical shift calibration check, the distribution of peak widths, and the distribution of intensities at baseline and surrounding the residual water peak.\n",
    "        <br/><br/>\n",
    "        Any samples which fall outside the pre-set thresholds for any of these analytical parameters are flagged (final table) and subsequently marked for exclusion from the dataset.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(nmrData,'feature summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Remove samples which fail based on any of the above analytical criteria by applying the sample masks.\n",
    "        <br/><br/>\n",
    "        At this point we can also exclude any other samples which are not required by setting preferences with the 'sampleTypes' argument. In this example, we limit our dataset to study samples and quality control samples only.\n",
    "        <br/><br/>\n",
    "        To keep all features, set the 'filterFeatures' argument to False.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrData.updateMasks(sampleTypes=[SampleType.StudySample, SampleType.StudyPool], filterFeatures=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Remove unwanted/uninformative regions of the spectrum (the defaults here are the TSP peak region and the region contaning the water pre-saturation signal) by updating the masks with 'filterFeatures=True'. Here, we also demonstrate removing an additional region between 8.4 and 8.5.\n",
    "        <br/><br/>\n",
    "        To keep all samples (as specified at the previous step) set the 'filterSamples' argument to False.\n",
    "        <br/><br/>\n",
    "        To summarise features retained/marked for exclusion use the feature summary report.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrData.updateMasks(filterSamples=False, filterFeatures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrData.updateMasks(filterSamples=False, filterFeatures=True, exclusionRegions=[(8.4, 8.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(nmrData,'feature summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanently exclude masked samples/features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "If happy with the samples and features masked for exclusion, apply these exclusions (permanently remove samples/features from the dataset) using the 'applyMasks' function.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrData.applyMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analytical Multivariate Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        The analytical multivariate report provides visualisations summarising the largest sources of variance in the dataset (by PCA) with particular emphasis on any potential analytical sources. Plots include:\n",
    "        <ul>\n",
    "        <li>Model statistics.</li>\n",
    "        <li>Scores plots. This provides insight into the relationship between sample, for example, consistency of the QC samples, sample outliers etc. </li>\n",
    "        <li>Loadings plots. This provides insight into the features with the largest variance in the dataset.</li>\n",
    "        <li>Potential associations with analytical parameters. Correlation (for continuous metadata) or Kruskal-Wallis test (for categorical metadata) between each metadata field and each set of PCA scores generated, any significant associations are flagged.</li>\n",
    "        <li>The default scaling is unit variance ('scaling=1'), but other scaling options are available (0 for means centering; 0.5 for Pareto scaling)</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAmodelAnalytical = nPYc.multivariate.exploratoryAnalysisPCA(nmrData, scaling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.multivariateQCreport(nmrData, PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Finalise & Export Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check final dataset output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(nmrData, 'final report', pcaModel=PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Export a unified csv file, which contains the intensity data (one row per sample, one column per variable), alongside all sample and feature metadata (left columns and top rows respectively).\n",
    "    <br/><br/>\n",
    "    Output the final report to provide a summary of the dataset.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmrData.exportDataset(saveFormat='UnifiedCSV', destinationPath=saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(nmrData, 'final report', pcaModel=PCAmodelAnalytical, destinationPath=saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
