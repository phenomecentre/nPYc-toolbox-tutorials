{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing LC-MS data with the nPYc-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This document provides a pipeline for the import of NMR data and any associated sample metadata, followed by summaries and quality control reports of the data, implementation of quality control analysis and output of a final dataset ready for sharing with collaborators and data modeling.\n",
    "\n",
    "#### By default all summary reports (with the exception of the final report) will be output only to this notebook. The notebook (including outputs) can be saved using >File>Save and Checkpoint. However, if html copies of any reports are required these can be automatically saved to the save directory by adding the optional input argument destinationPath=saveDir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Define the path to the raw data and corresponding metadata. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakPickedDataPath = '/path to peak picked data file/PipelineTest U RPOS xcms.csv'\n",
    "basicCSVPath = '/path to sample metadata file/PipelineTest U RPOS Basic CSV.csv'\n",
    "\n",
    "# rawDataPath = 'path to raw data files'\n",
    "\n",
    "saveDir = '/path to save outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Import the required Python libraries and the nPYc toolbox.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas\n",
    "import numpy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import nPYc\n",
    "import pyChemometrics\n",
    "import copy\n",
    "from nPYc.enumerations import VariableType, DatasetLevel, AssayRole, SampleType\n",
    "from nPYc.utilities.normalisation import NullNormaliser, TotalAreaNormaliser, ProbabilisticQuotientNormaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Data and Sample Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import acquired data and associated acqusition parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Import dataset (peak-picked in XCMS). Set the name of the 'dataset' object.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nPYc.MSDataset(peakPickedDataPath, fileType='XCMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.name = 'nPYc example PipelineTest U RPOS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Acquired Samples to Sample IDs and subject information (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Add corresponding sample metadata (including Sample IDs and any other sample specific information) and match to the acquired data, here sample metadata is in the 'Basic CSV' format.\n",
    "    <br/><br/>\n",
    "    Note, acquisition related parameters (for example, acquired time etc) can also be added by reading the raw data files (if available) using the 'addSampleInfo' function (line commented out below).\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.addSampleInfo(descriptionFormat='Basic CSV', filePath=basicCSVPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.addSampleInfo(descriptionFormat='Raw Data', filePath=rawDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features outside of the useful retention time range of the assay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Use the 'excludeFeatures' function to mark features outside of the useful RT range for exclusion. For the RPOS assay this corresponds to features with a retention time outside 0.6-10.5. \n",
    "        <br/><br/>\n",
    "        Subsequently, use the 'applyMasks' function to permanently remove these features from the dataset.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of original features: ' + str(sum(dataset.featureMask)))\n",
    "dataset.excludeFeatures(dataset.featureMetadata[dataset.featureMetadata['Retention Time'] > 10.5]['Feature Name'], on='Feature Name', message='Outside RT limits')\n",
    "dataset.excludeFeatures(dataset.featureMetadata[dataset.featureMetadata['Retention Time'] < 0.6]['Feature Name'], on='Feature Name', message='Outside RT limits')\n",
    "print('Number of features within RT range: ' + str(sum(dataset.featureMask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.applyMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sample & Feature Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate sample summary report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "       This summary can be used to check the expected samples against those acquired (for example, sample numbers, sample type, samples missing from acquisition or lacking metadata information).\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(dataset, 'sample summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feature summary report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        The feature summary report provides visualisations summarising the quality of the dataset and highlighting any problematic areas, including:\n",
    "        <ul>\n",
    "        <li>The distribution of feature intensities in each sample class.</li>\n",
    "        <li>The TIC in each sample against sample acqusition order, coloured by both sample class, and instrument gain parameter (detector voltage). This provides insight into potential run-order and batch effects.</li>\n",
    "        <li>The correlation of feature intensity to dilution and TIC in the dilution series. This provides insight into potential issues in correlation to dilution.</li>\n",
    "        <li>A histogram of feature RSDs, and a plot comparing the RSD measured in the different sample classes (study reference sample, study sanples etc). This provides insight into variance structures in the dataset, with the expectation that biologcal variance should exceeed analytical variance.</li>\n",
    "        <li>An ion map visualises the location of the detected features in the m/z and retention time space of the assay.</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(dataset,'feature summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess batch and run-order effects and apply correction if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Visualise feature intensity vs analysis order for a small subset of features in order to assess the need to correct batch and run-order effects. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(dataset, 'batch correction assessment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "       Apply correction if necessary.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetCorrected = nPYc.batchAndROCorrection.correctMSdataset(dataset, window=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Compare the dataset before and after correction.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(dataset, 'batch correction summary', msDataCorrected=datasetCorrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Generate the feature selection report to assess the number of features passing the quality control thresholds described in: <br/>\n",
    "        &emsp; Lewis et al, Development and Application of Ultra-Performance Liquid Chromatography-TOF MS for Precision Large Scale <br/> &emsp; Urinary Metabolic Phenotyping, Anal. Chem., 2016, 88 (18), pp 9004â€“9013\n",
    "        <br/><br/>\n",
    "        Filter the features based on these parameters using the 'updateMasks' function. To keep all samples, set the 'filterSamples' argument to False.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(datasetCorrected,'feature selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetCorrected.updateMasks(filterFeatures=True, filterSamples=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Remove samples which fail based on any of the above analytical criteria by applying the sample masks.\n",
    "        <br/><br/>\n",
    "        At this point we can also exclude any other samples which are not required by setting preferences with the 'sampleTypes' argument. In this example, we limit our dataset to study samples and quality control samples only.\n",
    "        <br/><br/>\n",
    "        To keep all features, set the 'filterFeatures' argument to False.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCorrected.updateMasks(sampleTypes=[SampleType.StudySample, SampleType.StudyPool], filterSamples=True, filterFeatures=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanently exclude masked samples/features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "If happy with the samples and features masked for exclusion, apply these exclusions (permanently remove samples/features from the dataset) using the 'applyMasks' function.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCorrected.applyMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analytical Multivariate Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        The analytical multivariate report provides visualisations summarising the largest sources of variance in the dataset (by PCA) with particular emphasis on any potential analytical sources. Plots include:\n",
    "        <ul>\n",
    "        <li>Model statistics.</li>\n",
    "        <li>Scores plots. This provides insight into the relationship between sample, for example, consistency of the QC samples, sample outliers etc. </li>\n",
    "        <li>Loadings plots. This provides insight into the features with the largest variance in the dataset.</li>\n",
    "        <li>Potential associations with analytical parameters. Correlation (for continuous metadata) or Kruskal-Wallis test (for categorical metadata) between each metadata field and each set of PCA scores generated, any significant associations are flagged.</li>\n",
    "        <li>The default scaling is unit variance ('scaling=1'), but other scaling options are available (0 for means centering; 0.5 for Pareto scaling)</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAmodelAnalytical = nPYc.multivariate.exploratoryAnalysisPCA(datasetCorrected, scaling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.multivariateQCreport(datasetCorrected, PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL: generate interactive scores and loadings plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Interactive scores plot:\n",
    "        <br/><br/>\n",
    "        For example, plot the scores for PCA components 1 vs. 2 and colour by Class.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nPYc.plotting.plotScoresInteractive(datasetCorrected, PCAmodelAnalytical, 'Class', components=[1, 2])\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "        Interactive loadings plot:\n",
    "        <br/><br/>\n",
    "        For example, plot the loadings for PCA component 2.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = nPYc.plotting.plotLoadingsInteractive(datasetCorrected, PCAmodelAnalytical, component=2)\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Finalise & Export Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check final dataset output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(datasetCorrected, 'final report', pcaModel=PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#EEFFEC'>\n",
    "    <font color='#0B6D01'>\n",
    "    Export a unified csv file, which contains the intensity data (one row per sample, one column per variable), alongside all sample and feature metadata (left columns and top rows respectively).\n",
    "    <br/><br/>\n",
    "    Output the final report to provide a summary of the dataset.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasetCorrected.exportDataset(saveFormat='UnifiedCSV', destinationPath=saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(datasetCorrected, 'final report', pcaModel=PCAmodelAnalytical, destinationPath=saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
